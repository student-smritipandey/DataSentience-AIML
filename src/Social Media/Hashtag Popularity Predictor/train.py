import pandas as pd
import os
import pickle
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

from preprocess import clean_hashtag

# ğŸ“¥ Load dataset
df = pd.read_csv("data/trending_hashtags.csv")
print("ğŸ“Š Columns in the dataset:", df.columns.tolist())

# ğŸ§¼ Clean hashtag column
df['hashtag'] = df['hashtag'].astype(str).apply(clean_hashtag)

# ğŸ§¹ Drop missing values
df = df.dropna(subset=['hashtag', 'mentions', 'estimated_reach', 'sentiment_score'])

# ğŸ¯ Create binary label: 1 if high reach, else 0
threshold = df['estimated_reach'].median()
df['is_trending'] = (df['estimated_reach'] > threshold).astype(int)

# ğŸ“¦ Feature matrix
X = df[['hashtag', 'mentions', 'sentiment_score']]
y = df['is_trending']

# ğŸ” Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('tag_tfidf', TfidfVectorizer(max_features=1000), 'hashtag'),
        ('scaler', StandardScaler(), ['mentions', 'sentiment_score'])
    ]
)

# ğŸ§ª Transform features
X_processed = preprocessor.fit_transform(X)

# âœ‚ï¸ Split
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

# ğŸ§  Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ğŸ“Š Evaluation
y_pred = model.predict(X_test)
print("ğŸ§  Classification Report:")
print(classification_report(y_test, y_pred))

# ğŸ’¾ Save
os.makedirs("models", exist_ok=True)
with open("models/popularity_model.pkl", "wb") as f:
    pickle.dump((preprocessor, model), f)

print("âœ… Model trained and saved at models/popularity_model.pkl")
