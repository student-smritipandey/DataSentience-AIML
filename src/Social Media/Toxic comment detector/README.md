# ğŸ§  Toxic Comment Detector

A multi-label NLP classifier that detects toxic behavior in user-generated comments. Built using the [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) dataset, this project flags toxic, threatening, and obscene language to improve online community safety.

[!ui screenshot](assets/image.png)
---

## ğŸ” Features

- âœ… Multi-label classification (`toxic`, `obscene`, `threat`, `insult`, etc.)
- âœ… TF-IDF vectorization + Logistic Regression baseline
- âœ… Modular code for training and prediction
- âœ… Easy extension to transformer models (e.g., BERT)
- âœ… Clean CLI-based interface for demo testing

---


